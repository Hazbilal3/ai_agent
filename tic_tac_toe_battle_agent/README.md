
# ğŸ® Tic Tac Toe Battle Agent (AI vs AI)

An interactive **AI vs AI Tic-Tac-Toe game** where two autonomous agents powered by different Large Language Models (LLMs) compete against each other.

This project is built using the **Agno Agent Framework** for multi-agent coordination and **Streamlit** for the interactive web UI.

---

## ğŸš€ Project Highlights

This project demonstrates how to:

- Coordinate **multiple AI agents** in a turn-based game
- Use **different LLMs** for each player
- Manage **game state & rule validation**
- Build a **real-time interactive UI** with Streamlit
- Track **move history and board states**
- Compare strategies of different AI models

---

## âœ¨ Features

- ğŸ¤– AI vs AI gameplay (Agent X vs Agent O)
- ğŸ” Turn-based coordination via Master (Referee) Agent
- ğŸ§  Supports multiple LLM providers
- ğŸ“Š Move history with board visualization
- ğŸ¯ Real-time board updates
- ğŸ”„ Reset & replay functionality
- ğŸ§ª Strategy & performance comparison

---

## ğŸ§  Supported AI Models

- **OpenAI** â€“ GPT-4o, o3-mini  
- **Anthropic** â€“ Claude  
- **Google** â€“ Gemini  
- **Groq** â€“ LLaMA 3  

> You can assign **different models to each player** and observe how they perform against each other.

---

## ğŸ—ï¸ Architecture Overview

The game uses **three agents**:

### 1ï¸âƒ£ Master Agent (Referee)
- Controls game flow
- Validates moves
- Maintains board state
- Detects win / draw conditions

### 2ï¸âƒ£ Player Agent X
- Analyzes board
- Makes strategic moves
- Uses selected AI model

### 3ï¸âƒ£ Player Agent O
- Responds to opponent moves
- Follows game rules
- Uses a different AI model (optional)

---

## ğŸ“¦ Project Structure

```bash
tic_tac_toe_battle_agent/
â”‚
â”œâ”€â”€ app.py                  # Streamlit UI & game runner
â”œâ”€â”€ agents/                 # AI agents (Master & Players)
â”œâ”€â”€ utils/                  # Game logic & helpers
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env.example            # Environment variable template
â””â”€â”€ README.md               # Project documentation
````

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Hazbilal3/ai_agent.git
cd tic_tac_toe_battle_agent
```

---

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Setup API Keys

Create a `.env` file in the project root:

```bash
touch .env
```

Add your API keys:

```env
# OpenAI (Required for GPT models)
OPENAI_API_KEY=your_openai_api_key

# Optional Providers
ANTHROPIC_API_KEY=your_anthropic_key
GOOGLE_API_KEY=your_google_key
GROQ_API_KEY=your_groq_key
```

âš ï¸ **Note:**

* Only add keys for models you plan to use
* The app will show helpful errors if a key is missing

---

### 4ï¸âƒ£ Run the Application

```bash
streamlit run app.py
```

Open your browser and go to:
ğŸ‘‰ **[http://localhost:8501](http://localhost:8501)**

---

## ğŸ® How to Play

1. Select AI models for **Agent X** and **Agent O**
2. Start the game
3. Watch both AI agents compete in real time
4. View:

   * Board updates
   * Move history
   * Game outcome (Win / Draw)

---

## ğŸ“Š Game Insights

* Compare decision-making between different LLMs
* Observe strategy patterns
* Analyze move timing & efficiency

---

## ğŸ§ª Use Cases

* Learning **multi-agent AI systems**
* Comparing LLM reasoning abilities
* Autonomous game-playing research
* Streamlit + AI agent integration demo

---

## ğŸ› ï¸ Tech Stack

* **Python**
* **Streamlit**
* **Agno Agent Framework**
* **OpenAI / Anthropic / Google / Groq APIs**

---

## ğŸ“Œ Future Improvements

* Human vs AI mode
* Difficulty levels
* Tournament mode
* Game analytics dashboard
* Reinforcement learning integration

---

## ğŸ‘¤ Author

**Hazbilal**
ğŸ”— GitHub: [https://github.com/Hazbilal3](https://github.com/Hazbilal3)

---

â­ If you like this project, don't forget to **star the repository**!


